import sys

import torch
import matplotlib.pyplot as plt
import numpy as np
import cv2
import os
from torch.utils.data import DataLoader, Subset

sys.path.append('../')

from data_process.dataset import PIDA_dataset, Masked_Dataset, Normal_Dataset, Occlusion_Dataset, Tennis_Dataset, Event_Dataset
from data_process.data_utils import get_all_detection_infor, train_val_data_separation, get_all_detection_infor_tennis, get_events_infor_noseg
from data_process.transformation import Compose, Random_Crop, Resize, Normalize, Random_Rotate, Random_HFlip, Random_VFlip, Random_Ball_Mask, RandomColorJitter


def create_train_val_dataloader(configs):
    """Create dataloader for training and validate"""

    train_transform = Compose([
        Random_Crop(max_reduction_percent=0.15, p=0.5),
        Random_HFlip(p=0.5),
        Random_Rotate(rotation_angle_limit=10, p=0.5),
    ], p=1.)

    train_events_infor, val_events_infor, train_events_label, val_events_label = train_val_data_separation(configs)
    train_dataset = PIDA_dataset(train_events_infor, train_events_label, transform=train_transform,
                                  num_samples=configs.num_samples)
    train_sampler = None
    if configs.distributed:
        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)
    train_dataloader = DataLoader(train_dataset, batch_size=configs.batch_size, shuffle=(train_sampler is None),
                                  pin_memory=configs.pin_memory, num_workers=configs.num_workers, sampler=train_sampler)

    val_dataloader = None
    if not configs.no_val:
 
        val_transform = None
        val_sampler = None
        val_dataset = PIDA_dataset(val_events_infor, val_events_label, transform=val_transform,
                                    num_samples=configs.num_samples)
        if configs.distributed:
            val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, shuffle=False)
        val_dataloader = DataLoader(val_dataset, batch_size=configs.batch_size, shuffle=False,
                                    pin_memory=configs.pin_memory, num_workers=configs.num_workers, sampler=val_sampler)

    return train_dataloader, val_dataloader, train_sampler

def create_test_dataloader(configs):
    """Create dataloader for testing phase"""

    test_transform = None
    dataset_type = 'test'
    test_events_infor, test_events_labels = get_all_detection_infor(configs.test_game_list, configs, dataset_type)
    test_dataset = PIDA_dataset(test_events_infor, test_events_labels, transform=test_transform,
                                 num_samples=configs.num_samples)
    test_sampler = None
    if configs.distributed:
        test_sampler = torch.utils.data.distributed.DistributedSampler(test_dataset)
    test_dataloader = DataLoader(test_dataset, batch_size=configs.batch_size, shuffle=False,
                                 pin_memory=configs.pin_memory, num_workers=configs.num_workers, sampler=test_sampler)

    return test_dataloader


def create_masked_train_val_dataloader(configs, subset_size=None):
    """Create dataloader for training and validation, with an option to use a subset of the data."""

    train_transform = Compose([
        Resize(new_size=configs.img_size, p=1.0),
        Random_Ball_Mask(mask_size=(20,20), p=0.25),
    ], p=1.)

    # Load train and validation data information
    train_events_infor, val_events_infor, train_events_label, val_events_label = train_val_data_separation(configs)

    # Create train dataset
    train_dataset = Masked_Dataset(train_events_infor, train_events_label, transform=train_transform,
                                   num_samples=configs.num_samples)
    
    # If subset_size is provided, create a subset for training
    if subset_size is not None:
        train_indices = torch.randperm(len(train_dataset))[:subset_size].tolist()
        train_dataset = Subset(train_dataset, train_indices)
    
    # Create train sampler if distributed
    train_sampler = None
    if configs.distributed:
        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)
    
    # Create train dataloader
    train_dataloader = DataLoader(train_dataset, batch_size=configs.batch_size, shuffle=(train_sampler is None),
                                  pin_memory=configs.pin_memory, num_workers=configs.num_workers, 
                                  sampler=train_sampler, drop_last=True)

    # Create validation dataloader (without transformations)
    val_dataloader = None
    if not configs.no_val:
        val_transform = Compose([
            Resize(new_size=configs.img_size, p=1.0),
        ], p=1.)
        val_dataset = Masked_Dataset(val_events_infor, val_events_label, transform=val_transform,
                                     num_samples=configs.num_samples)

        # If subset_size is provided, create a subset for validation
        if subset_size is not None:
            val_indices = torch.randperm(len(val_dataset))[:subset_size].tolist()
            val_dataset = Subset(val_dataset, val_indices)
        
        # Create validation sampler if distributed
        val_sampler = None
        if configs.distributed:
            val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, shuffle=False)
        
        # Create validation dataloader
        val_dataloader = DataLoader(val_dataset, batch_size=configs.batch_size, shuffle=False,
                                    pin_memory=configs.pin_memory, num_workers=configs.num_workers, sampler=val_sampler, drop_last=True)

    return train_dataloader, val_dataloader, train_sampler

def create_masked_test_dataloader(configs):
    """Create dataloader for testing phase"""

    test_transform = Compose([
            Resize(new_size=configs.img_size, p=1.0),
        ], p=1.)
    dataset_type = 'test'
    test_events_infor, test_events_labels = get_all_detection_infor(configs.test_game_list, configs, dataset_type)
    test_dataset = Masked_Dataset(test_events_infor, test_events_labels, transform=test_transform,
                                 num_samples=configs.num_samples)
    test_sampler = None
    if configs.distributed:
        test_sampler = torch.utils.data.distributed.DistributedSampler(test_dataset)
    test_dataloader = DataLoader(test_dataset, batch_size=configs.batch_size, shuffle=False,
                                 pin_memory=configs.pin_memory, num_workers=configs.num_workers, 
                                 sampler=test_sampler, drop_last=True)

    return test_dataloader


def create_normal_train_val_dataloader(configs, subset_size=None):
    """Create dataloader for training and validation, with an option to use a subset of the data."""

    train_transform = Compose([
        Resize(new_size=configs.img_size, p=1.0),
        Random_Crop(max_reduction_percent=0.15, p=0.5),
        Random_HFlip(p=0.5),
        Random_VFlip(p=0.5),
        Random_Rotate(rotation_angle_limit=10, p=0.5),
    ], p=1.)

    # Load train and validation data information
    train_events_infor, val_events_infor, train_events_label, val_events_label = train_val_data_separation(configs)

    # Create train dataset
    train_dataset = Normal_Dataset(train_events_infor, train_events_label, transform=train_transform,
                                   num_samples=configs.num_samples)
    
    # If subset_size is provided, create a subset for training
    if subset_size is not None:
        train_indices = torch.randperm(len(train_dataset))[:subset_size].tolist()
        train_dataset = Subset(train_dataset, train_indices)
    
    # Create train sampler if distributed
    train_sampler = None
    if configs.distributed:
        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)
    
    # Create train dataloader
    train_dataloader = DataLoader(train_dataset, batch_size=configs.batch_size, shuffle=(train_sampler is None),
                                  pin_memory=configs.pin_memory, num_workers=configs.num_workers, sampler=train_sampler, drop_last=True)

    # Create validation dataloader (without transformations)
    val_dataloader = None
    if not configs.no_val:
        val_transform = Compose([
            Resize(new_size=configs.img_size, p=1.0),
        ], p=1.)
        val_dataset = Normal_Dataset(val_events_infor, val_events_label, transform=val_transform,
                                     num_samples=configs.num_samples)

        # If subset_size is provided, create a subset for validation
        if subset_size is not None:
            val_indices = torch.randperm(len(val_dataset))[:subset_size].tolist()
            val_dataset = Subset(val_dataset, val_indices)
        
        # Create validation sampler if distributed
        val_sampler = None
        if configs.distributed:
            val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, shuffle=False)
        
        # Create validation dataloader
        val_dataloader = DataLoader(val_dataset, batch_size=configs.batch_size, shuffle=False,
                                    pin_memory=configs.pin_memory, num_workers=configs.num_workers, sampler=val_sampler, drop_last=True)

    return train_dataloader, val_dataloader, train_sampler

def create_normal_test_dataloader(configs):
    """Create dataloader for testing phase"""

    test_transform = Compose([
            Resize(new_size=configs.img_size, p=1.0),
        ], p=1.)
    dataset_type = 'test'
    test_events_infor, test_events_labels = get_all_detection_infor(configs.test_game_list, configs, dataset_type)
    test_dataset = Normal_Dataset(test_events_infor, test_events_labels, transform=test_transform,
                                 num_samples=configs.num_samples)
    test_sampler = None
    if configs.distributed:
        test_sampler = torch.utils.data.distributed.DistributedSampler(test_dataset)
    test_dataloader = DataLoader(test_dataset, batch_size=configs.batch_size, shuffle=False,
                                 pin_memory=configs.pin_memory, num_workers=configs.num_workers, sampler=test_sampler, drop_last=True)

    return test_dataloader


def create_occlusion_train_val_dataloader(configs, subset_size=None, necessary_prob=1.0):
    """Create dataloader for training and validation, with an option to use a subset of the data."""

    train_transform = Compose([
        RandomColorJitter(p=0.25),
        Random_Ball_Mask(mask_size=(configs.img_size[0]//10,configs.img_size[0]//10), p=configs.occluded_prob),
        Random_Crop(max_reduction_percent=0.2, p=0.25),
        Resize(new_size=configs.img_size, p=necessary_prob),
        Normalize(num_frames_sequence=configs.num_frames, p=necessary_prob),
    ], p=1.)

    
    # Load train and validation data information
    train_events_infor, val_events_infor, train_events_label, val_events_label = train_val_data_separation(configs)

    if configs.dataset_choice == 'tt':
        # Create train dataset
        if configs.event:
            train_dataset = Event_Dataset(train_events_infor, train_events_label, transform=train_transform,
                                    num_samples=configs.num_samples)
        else:
            train_dataset = Occlusion_Dataset(train_events_infor, train_events_label, transform=train_transform,
                                        num_samples=configs.num_samples)
    else:
        train_dataset = Tennis_Dataset(train_events_infor, train_events_label, transform=train_transform,
                                    num_samples=configs.num_samples)
    # If subset_size is provided, create a subset for training
    if subset_size is not None:
        train_indices = torch.randperm(len(train_dataset))[:subset_size].tolist()
        train_dataset = Subset(train_dataset, train_indices)
    
    # Create train sampler if distributed
    train_sampler = None
    if configs.distributed:
        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)
    
    # Create train dataloader
    train_dataloader = DataLoader(train_dataset, batch_size=configs.batch_size, shuffle=(train_sampler is None),
                                  pin_memory=configs.pin_memory, num_workers=configs.num_workers, 
                                  sampler=train_sampler, drop_last=False)

    # Create validation dataloader (without transformations)
    val_dataloader = None
    if not configs.no_val:
        val_transform = Compose([
            Resize(new_size=configs.img_size, p=necessary_prob),
            Normalize(num_frames_sequence=configs.num_frames, p=necessary_prob),
        ], p=1.)

        if configs.dataset_choice == 'tt':
            if configs.event:
                val_dataset = Event_Dataset(val_events_infor, val_events_label, transform=val_transform,
                                            num_samples=configs.num_samples)
            else:
                val_dataset = Occlusion_Dataset(val_events_infor, val_events_label, transform=val_transform,
                                            num_samples=configs.num_samples)
        else:
            val_dataset = Tennis_Dataset(val_events_infor, val_events_label, transform=val_transform,
                                        num_samples=configs.num_samples)
        # If subset_size is provided, create a subset for validation
        if subset_size is not None:
            val_indices = torch.randperm(len(val_dataset))[:subset_size].tolist()
            val_dataset = Subset(val_dataset, val_indices)
        
        # Create validation sampler if distributed
        val_sampler = None
        if configs.distributed:
            val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, shuffle=False)
        
        # Create validation dataloader
        val_dataloader = DataLoader(val_dataset, batch_size=configs.batch_size, shuffle=False,
                                    pin_memory=configs.pin_memory, num_workers=configs.num_workers, sampler=val_sampler, drop_last=False)

    return train_dataloader, val_dataloader, train_sampler

def create_occlusion_test_dataloader(configs, subset_size=None):
    """Create dataloader for testing phase"""

    test_transform = Compose([
            Resize(new_size=configs.img_size, p=1.0),
            Normalize(num_frames_sequence=configs.num_frames, p=1.0),
        ], p=1.)
    dataset_type = 'test'
    if configs.dataset_choice == 'tt':
        if configs.event:
            test_events_infor, test_events_labels = get_events_infor_noseg(configs.test_game_list, configs, dataset_type)
            test_dataset = Event_Dataset(test_events_infor, test_events_labels, transform=test_transform,
                                 num_samples=configs.num_samples)
        else:
            test_events_infor, test_events_labels = get_all_detection_infor(configs.test_game_list, configs, dataset_type)
            test_dataset = Occlusion_Dataset(test_events_infor, test_events_labels, transform=test_transform,
                                    num_samples=configs.num_samples)
    else:
        test_events_infor, test_events_labels = get_all_detection_infor_tennis(configs.tennis_test_game_list, configs)
        test_dataset = Tennis_Dataset(test_events_infor, test_events_labels, transform=test_transform,
                                 num_samples=configs.num_samples)
    test_sampler = None

    # If subset_size is provided, create a subset for training
    if subset_size is not None:
        test_indices = torch.randperm(len(test_dataset))[:subset_size].tolist()
        test_dataset = Subset(test_dataset, test_indices)

    if configs.distributed:
        test_sampler = torch.utils.data.distributed.DistributedSampler(test_dataset)
    test_dataloader = DataLoader(test_dataset, batch_size=configs.batch_size, shuffle=False,
                                 pin_memory=configs.pin_memory, num_workers=configs.num_workers, 
                                 sampler=test_sampler, drop_last=False)

    return test_dataloader


def draw_image_with_ball(image_tensor, ball_location_tensor, out_images_dir, example_index):
    # Convert tensors to numpy arrays

    image = image_tensor.permute(1, 2, 0).cpu().numpy()  # Convert from (C, H, W) to (H, W, C)
    ball_location = ball_location_tensor.cpu().numpy()    # Ensure ball location is on CPU

    # Ensure the image is in uint8 format for OpenCV
    if image.dtype != 'uint8':
        image = (image * 255).astype('uint8')

    # Draw the ball on the image
    ball_xy = tuple(ball_location.astype(int))  # Convert coordinates to int
    img_with_ball = cv2.circle(image.copy(), ball_xy, radius=5, color=(255, 0, 0), thickness=2)

    # Convert the image to BGR format for saving with OpenCV
    img_with_ball = cv2.cvtColor(img_with_ball, cv2.COLOR_RGB2BGR)

    # Save the image
    output_path = os.path.join(out_images_dir, f'example_label_{example_index}.jpg')
    cv2.imwrite(output_path, img_with_ball)

    return output_path  # Optionally return the saved path

def concatenate_images_horizontally(images):
    """
    Concatenate a list of images horizontally.
    Args:
        images (list): List of images (numpy arrays) to concatenate.
    Returns:
        concatenated_image: Combined image as a single numpy array.
    """
    return cv2.hconcat(images)

if __name__ == '__main__':
    from config.config import parse_configs

    configs = parse_configs()
    configs.distributed = False  # For testing
    configs.batch_size = 1
    configs.img_size = (288, 512)
    configs.interval = 1
    configs.num_frames = 5
    configs.occluded_prob = 0

    configs.dataset_choice = 'tt'
    configs.event = True
    # configs.smooth_labelling = True


    # Create Masked dataloaders 
    train_dataloader, val_dataloader, train_sampler = create_occlusion_train_val_dataloader(configs, necessary_prob=0)
    print('len train_dataloader: {}, val_dataloader: {}'.format(len(train_dataloader), len(val_dataloader)))
    
    test_dataloader = create_occlusion_test_dataloader(configs, configs.num_samples)
    print(f"len test_loader {len(test_dataloader)}")

    frame_id = configs.num_frames-1

    if configs.event == False:
        batch_data, (masked_frameids, ball_xys, visability, status) = next(iter(train_dataloader))
    else:
        batch_data, (masked_frameids, ball_xys, target_events, event_classes) = next(iter(train_dataloader))
    
    if configs.event or configs.bidirect:
        frame_id = configs.num_frames//2
    # print(f"unique number of batch_data is {torch.unique(batch_data)}")
    # Check the shapes
    print(f'ball frame is {frame_id}, print event is {event_classes}')
    print(f'Batch data shape: {batch_data.shape}')      # Expected: [B, N, C, H, W]
    print(f'Batch ball_xy shape: {ball_xys.shape}')  # Expected: [8, 2], 2 represents X and Y of the coordinaties 
    print(torch.unique(ball_xys))
   
    # Select the first sample in the batch
    sample_data = batch_data[0]  # Shape: [B, C, H, W]

    # Select the first frame
    img = sample_data[0]  # Shape: [C, H, W]

    # Transpose the dimensions to [H, W, C]
    image = np.transpose(img, (1, 2, 0))  # Shape: [H, W, C]
    image = image.cpu().numpy()
    
    out_images_dir = os.path.join(configs.results_dir, 'debug', 'ttnet_dataset')
    if not os.path.isdir(out_images_dir):
        os.makedirs(out_images_dir)
    cv2.imwrite(os.path.join(out_images_dir, f'example.jpg'), image)

    # Loop over each sample in the batch
    for batch_index in range(batch_data.shape[0]):
        sample_data = batch_data[batch_index]  # Shape: [N, C, H, W]
        masked_image = sample_data[frame_id]  # Shape: [C, H, W]
        ball_xy = ball_xys[batch_index].cpu().numpy()  # Ball coordinates for this sample, as a list

        # Collect all frames (original and masked) for visualization
        frame_images = []

        for frame_index in range(sample_data.shape[0]):
            img = sample_data[frame_index]  # Shape: [C, H, W]
            image = np.transpose(img.cpu().numpy(), (1, 2, 0))  # Convert to [H, W, C]
            frame_images.append(image)

        # Add the masked frame with ball position
        masked_frame = np.transpose(masked_image.cpu().numpy(), (1, 2, 0))  # Convert to [H, W, C]
        img_with_ball = cv2.circle(masked_frame.copy(), tuple(ball_xy), radius=10, color=(0, 0, 255), thickness=3)
        # img_with_ball = cv2.cvtColor(img_with_ball, cv2.COLOR_RGBR)  # Convert to BGR for saving
        frame_images.append(img_with_ball)  # Add the masked frame to the list

        # Concatenate all frames horizontally
        combined_image = concatenate_images_horizontally(frame_images)

        # Save the combined image
        output_path = os.path.join(out_images_dir, f'test_batch_{batch_index}_combined.jpg')
        cv2.imwrite(output_path, combined_image)

    print("All combined images saved successfully.")